{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a43d5fa",
   "metadata": {},
   "source": [
    "Jeyner Arango 201106\n",
    "\n",
    "Oscar MÃ©ndez 20402"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51a5d18",
   "metadata": {},
   "source": [
    "# Laboratorio 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87cea221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\osjom\\AppData\\Local\\Temp\\ipykernel_31760\\2611132405.py:15: UserWarning: \n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "  import dash_core_components as dcc\n",
      "C:\\Users\\osjom\\AppData\\Local\\Temp\\ipykernel_31760\\2611132405.py:16: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from afinn import Afinn\n",
    "\n",
    "import plotly.express as px\n",
    "import dash\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2612458",
   "metadata": {},
   "source": [
    "## Procesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea2ac1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\osjom\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\osjom\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "english_stop_words = stopwords.words('english')\n",
    "pd.set_option('display.max_colwidth', 140)\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "849e5ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    \"\"\" \n",
    "    removemos handles @user, links https, numeros,\n",
    "    pasamos a minuscula, removemos numeros, partimos texto,\n",
    "    eliminamos espacios innecesarios y volvemos a unir texto \n",
    "\n",
    "    @return texto limpio\n",
    "    \"\"\"\n",
    "    tweet = tweet.replace(\"%20\", \" \").replace(\"&amp;\", \"&\")\n",
    "    user_removed = re.sub(r'@[A-Za-z0-9]+','',tweet)\n",
    "    link_removed = re.sub('https?://[A-Za-z0-9./]+','',user_removed)\n",
    "    number_removed = re.sub('[^a-zA-Z]', ' ', link_removed)\n",
    "    lower_case_tweet= number_removed.lower()\n",
    "    tok = WordPunctTokenizer()\n",
    "    words = tok.tokenize(lower_case_tweet)\n",
    "    clean_tweet = (' '.join(words)).strip()\n",
    "    return clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a06d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(tweet):\n",
    "    removed_stop_words = ' '.join([word for word in tweet.split() if word not in english_stop_words])\n",
    "    return removed_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adfa7d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tweet(tweet):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in tweet.split()]\n",
    "    lemmatized_tweet = ' '.join(lemmatized_words)\n",
    "    return lemmatized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a665a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_length'] = df['text'].apply(len)\n",
    "df['text'] = df['text'].apply(clean_tweets).apply(lemmatize_tweet).apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4acb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn = Afinn()\n",
    "df['text_sentiment'] = df['text'].apply(afinn.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0ffae7",
   "metadata": {},
   "source": [
    "## Analisis de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "884f888b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_length</th>\n",
       "      <th>text_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resident asked shelter place notified officer evacuation shelter place order expected</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfire evacuation order california</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pours school</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   1     NaN      NaN   \n",
       "1   4     NaN      NaN   \n",
       "2   5     NaN      NaN   \n",
       "3   6     NaN      NaN   \n",
       "4   7     NaN      NaN   \n",
       "\n",
       "                                                                                    text  \\\n",
       "0                                             deed reason earthquake may allah forgive u   \n",
       "1                                                  forest fire near la ronge sask canada   \n",
       "2  resident asked shelter place notified officer evacuation shelter place order expected   \n",
       "3                                    people receive wildfire evacuation order california   \n",
       "4                                 got sent photo ruby alaska smoke wildfire pours school   \n",
       "\n",
       "   target  text_length  text_sentiment  \n",
       "0       1           69             1.0  \n",
       "1       1           38            -2.0  \n",
       "2       1          133            -1.0  \n",
       "3       1           65            -1.0  \n",
       "4       1           88             0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7e9b57",
   "metadata": {},
   "source": [
    "## Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c03d766",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1f10199f590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app = dash.Dash(__name__, external_stylesheets=['https://codepen.io/chriddyp/pen/bWLwgP.css'])\n",
    "\n",
    "app.layout = html.Div(children=[\n",
    "    html.H1(children='Tweets', style={'textAlign': 'center', 'fontFamily': 'Poppins', 'color': '#e4eef2'}),\n",
    "    \n",
    "    # Filter for the target\n",
    "    html.Div(children=[\n",
    "        dcc.Checklist(\n",
    "            id='target-checklist',\n",
    "            options=[\n",
    "                {'label': 'Target 0', 'value': 0},\n",
    "                {'label': 'Target 1', 'value': 1}\n",
    "            ],\n",
    "            value=[0, 1]\n",
    "        )\n",
    "    ], style={'textAlign': 'center', 'fontFamily': 'Poppins', 'color': '#e4eef2'}),\n",
    "\n",
    "    html.Div([\n",
    "        # Countplot of the country (top 10)\n",
    "        html.Div(children=[\n",
    "            dcc.Graph(\n",
    "                id='country-countplot'\n",
    "            )\n",
    "        ], style={'width': '50%', 'display': 'inline-block', 'fontFamily': 'Poppins'}),\n",
    "\n",
    "        # Distribution plot for the sentiment\n",
    "        html.Div(children=[\n",
    "            dcc.Graph(\n",
    "                id='sentiment-distribution-plot'\n",
    "            )\n",
    "        ], style={'width': '50%', 'display': 'inline-block', 'fontFamily': 'Poppins'})\n",
    "    ]),\n",
    "\n",
    "    html.Div([\n",
    "        # Countplot of the keyword (top 10)\n",
    "        html.Div(children=[\n",
    "            dcc.Graph(\n",
    "                id='keyword-countplot'\n",
    "            )\n",
    "        ], style={'width': '50%', 'display': 'inline-block', 'fontFamily': 'Poppins'}),\n",
    "\n",
    "        # Distribution plot of the text length\n",
    "        html.Div(children=[\n",
    "            dcc.Graph(\n",
    "                id='text-length-distribution-plot'\n",
    "            )\n",
    "        ], style={'width': '50%', 'display': 'inline-block', 'fontFamily': 'Poppins'})\n",
    "    ], style={'fontFamily': 'Poppins'})\n",
    "], style={'fontFamily': 'Poppins', 'backgroundColor': '#111212'})\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    [Output('country-countplot', 'figure'),\n",
    "     Output('sentiment-distribution-plot', 'figure'),\n",
    "     Output('keyword-countplot', 'figure'),\n",
    "     Output('text-length-distribution-plot', 'figure')],\n",
    "    [Input('target-checklist', 'value')]\n",
    ")\n",
    "def update_plots(selected_targets):\n",
    "    filtered_df = df[df['target'].isin(selected_targets)]\n",
    "\n",
    "    country_countplot = px.bar(filtered_df['location'].value_counts()[:10], title='Country Count').update_layout(\n",
    "        xaxis_title=\"Country\",\n",
    "        yaxis_title=\"Count\",\n",
    "        template=\"plotly_dark\"\n",
    "    )\n",
    "\n",
    "    sentiment_distribution_plot = px.histogram(filtered_df, x=\"text_sentiment\", title=\"Sentiment Distribution\").update_layout(\n",
    "        xaxis_title=\"Sentiment\",\n",
    "        yaxis_title=\"Frequency\",\n",
    "        template=\"plotly_dark\"\n",
    "    )\n",
    "\n",
    "    keyword_countplot = px.bar(filtered_df['keyword'].value_counts()[:10], title='Keyword Count').update_layout(\n",
    "        xaxis_title=\"Keyword\",\n",
    "        yaxis_title=\"Count\",\n",
    "        template=\"plotly_dark\"\n",
    "    )\n",
    "\n",
    "    text_length_distribution_plot = px.histogram(filtered_df, x=\"text_length\", title=\"Text Length Distribution\").update_layout(\n",
    "        xaxis_title=\"Text Length\",\n",
    "        yaxis_title=\"Frequency\",\n",
    "        template=\"plotly_dark\"\n",
    "    )\n",
    "\n",
    "    return country_countplot, sentiment_distribution_plot, keyword_countplot, text_length_distribution_plot\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
