{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb89460",
   "metadata": {},
   "source": [
    "Jeyner Arango 201106\n",
    "\n",
    "Oscar MÃ©ndez 20402"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca088c79",
   "metadata": {},
   "source": [
    "# Laboratorio 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42e560ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import emoji, nltk\n",
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from afinn import Afinn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bc26742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dash import Dash, html, jupyter_dash\n",
    "import dash_core_components as dcc\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e5a26a",
   "metadata": {},
   "source": [
    "## Procesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ee9b565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\osjom\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\osjom\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "english_stop_words = stopwords.words('english')\n",
    "pd.set_option('display.max_colwidth', 140)\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "508ed088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    \"\"\" \n",
    "    removemos handles @user, links https, numeros,\n",
    "    pasamos a minuscula, removemos numeros, partimos texto,\n",
    "    eliminamos espacios innecesarios y volvemos a unir texto \n",
    "\n",
    "    @return texto limpio\n",
    "    \"\"\"\n",
    "    tweet = tweet.replace(\"%20\", \" \").replace(\"&amp;\", \"&\")\n",
    "    user_removed = re.sub(r'@[A-Za-z0-9]+','',tweet)\n",
    "    link_removed = re.sub('https?://[A-Za-z0-9./]+','',user_removed)\n",
    "    number_removed = re.sub('[^a-zA-Z]', ' ', link_removed)\n",
    "    lower_case_tweet= number_removed.lower()\n",
    "    tok = WordPunctTokenizer()\n",
    "    words = tok.tokenize(lower_case_tweet)\n",
    "    clean_tweet = (' '.join(words)).strip()\n",
    "    return clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df568ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(tweet):\n",
    "    removed_stop_words = ' '.join([word for word in tweet.split() if word not in english_stop_words])\n",
    "    return removed_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "924f2c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tweet(tweet):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in tweet.split()]\n",
    "    lemmatized_tweet = ' '.join(lemmatized_words)\n",
    "    return lemmatized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d030f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_length'] = df['text'].apply(len)\n",
    "df['text'] = df['text'].apply(clean_tweets).apply(lemmatize_tweet).apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c8bd661",
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn = Afinn()\n",
    "df['text_sentiment'] = df['text'].apply(afinn.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deca7438",
   "metadata": {},
   "source": [
    "## Analisis de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cafd6505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_length</th>\n",
       "      <th>text_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resident asked shelter place notified officer evacuation shelter place order expected</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfire evacuation order california</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pours school</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   1     NaN      NaN   \n",
       "1   4     NaN      NaN   \n",
       "2   5     NaN      NaN   \n",
       "3   6     NaN      NaN   \n",
       "4   7     NaN      NaN   \n",
       "\n",
       "                                                                                    text  \\\n",
       "0                                             deed reason earthquake may allah forgive u   \n",
       "1                                                  forest fire near la ronge sask canada   \n",
       "2  resident asked shelter place notified officer evacuation shelter place order expected   \n",
       "3                                    people receive wildfire evacuation order california   \n",
       "4                                 got sent photo ruby alaska smoke wildfire pours school   \n",
       "\n",
       "   target  text_length  text_sentiment  \n",
       "0       1           69             1.0  \n",
       "1       1           38            -2.0  \n",
       "2       1          133            -1.0  \n",
       "3       1           65            -1.0  \n",
       "4       1           88             0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166fc1ab",
   "metadata": {},
   "source": [
    "## Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ceec566a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2edffb134d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the Dash app\n",
    "app = Dash(__name__)\n",
    "\n",
    "# Create a table\n",
    "def generate_table(dataframe, max_rows=10):\n",
    "    return html.Table([\n",
    "        html.Thead(\n",
    "            html.Tr([html.Th(col) for col in dataframe.columns])\n",
    "        ),\n",
    "        html.Tbody([\n",
    "            html.Tr([\n",
    "                html.Td(dataframe.iloc[i][col]) for col in dataframe.columns\n",
    "            ]) for i in range(min(len(dataframe), max_rows))\n",
    "        ])\n",
    "    ])\n",
    "\n",
    "# Define the layout of the app\n",
    "app.layout = html.Div(children=[\n",
    "    html.H1(children='Tweets'),\n",
    "\n",
    "    html.Div(children='''\n",
    "        Dash: A web application framework for Python.\n",
    "    '''),\n",
    "\n",
    "    # Display the DataFrame as a table\n",
    "    html.H3(children='Data Table'),\n",
    "    generate_table(df),\n",
    "\n",
    "    # Display a histogram of text lengths\n",
    "    dcc.Graph(\n",
    "        id='text-length-histogram',\n",
    "        figure=px.histogram(df, x=\"text_length\", nbins=20, title=\"Text Length Histogram\")\n",
    "    ),\n",
    "\n",
    "    # Display a bar chart of text sentiment values\n",
    "    dcc.Graph(\n",
    "        id='text-sentiment-bar',\n",
    "        figure=px.bar(df, x=\"id\", y=\"text_sentiment\", title=\"Text Sentiment Bar Chart\")\n",
    "    )\n",
    "])\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
